{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "    def forward(self, q, k, v, attention_mask):\n",
    "        ####Tensor dimension####################\n",
    "        #### q [batch_size, n_heads, len_q, d_k]\n",
    "        #### k [batch_size, n_heads, len_k, d_k]\n",
    "        #### v [batch_size, n_heads, len_v, d_v]\n",
    "        ####attension_mask [batch_size, n_heads, seq_len, seq_len]\n",
    "        ####\n",
    "        ####calculate score q and k\n",
    "        score = torch.matmul(q, k.transpose(-1, -2))/np.sqrt(self.d_k)\n",
    "        ####extend the length and fill a small number\n",
    "        score.masked_fill_(attention_mask, -1e10)\n",
    "        ####softmax with last dimension\n",
    "        attn = nn.Softmax(dim=-1)(score)     \n",
    "        ####After attension [batch_size, n_heads, len_q, d_v]\n",
    "        context = torch.matmul(attn, v)\n",
    "        return context, attn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_k, d_v):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.w_q = nn.Linear(d_model, d_k * n_heads, bias = False)\n",
    "        self.w_k = nn.Linear(d_model, d_k * n_heads, bias = False)\n",
    "        self.w_v = nn.Linear(d_model, d_v * n_heads, bias = False)\n",
    "        self.fc = nn.Linear(d_model, d_v * n_heads, bias = False)\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, q, k, v, attention_mask):\n",
    "        ####Tensor dimension####################\n",
    "        #### q [batch_size, n_heads, len_q, d_k]\n",
    "        #### k [batch_size, n_heads, len_k, d_k]\n",
    "        #### v [batch_size, n_heads, len_v, d_v]\n",
    "        ####attension_mask [batch_size, n_heads, seq_len, seq_len]\n",
    "        residual, batch_size = q, q.size(0)\n",
    "        ####calculate q, k, v####\n",
    "        q = self.w_q(q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        k = self.w_k(k).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        v = self.w_v(v).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        ####calculate attention mask####\n",
    "        attention_mask = attention_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1)\n",
    "        ####calculate score####\n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(q, k, v, attention_mask)\n",
    "        context = context.transpose(1,2).reshape(batch_size, -1, self.n_heads*self.d_v)\n",
    "        output = self.fc(context)\n",
    "        return self.layernorm(output+residual), attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "        nn.Linear(d_model, d_ff, bias = False),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_ff, d_model, bias = False)\n",
    "        )\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        ###inputs [batch_size, seq_len, d_model]\n",
    "        residual = inputs\n",
    "        output = self.fc(inputs)\n",
    "        return self.layernorm(output+residual)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, d_k, d_v):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Multi-head attention\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads, d_k, d_v)\n",
    "        # feedforward layer\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        \n",
    "    def forward(self, inputs, attention_mask):\n",
    "        ##\n",
    "        # inputs: [batch_size, seq_len, d_model]\n",
    "        # attention_mask: [batch_size, seq_len, seq_len]\n",
    "        ##\n",
    "        # outputs: [batch_size, seq_len, d_model]\n",
    "        # self_attn: [batch_size, n_heads, seq_len, seq_len]\n",
    "        outputs, self_attn = self.attention(inputs, inputs, inputs, attention_mask)\n",
    "        # [batch_size, seq_len, d_model]\n",
    "        outputs = self.pos_ffn(outputs)\n",
    "        return outputs, self_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_pos, device):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.device = device\n",
    "        self.pos_embedding = nn.Embedding(max_pos, d_model)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        seq_len = inputs.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long, device=self.device)\n",
    "        # [seq_len] -> [batch_size, seq_len]\n",
    "        pos = pos.unsqueeze(0).expand_as(inputs)\n",
    "        return self.pos_embedding(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_subsequence_mask(seq, device):\n",
    "    # attention score dimention [batch_size, n_heads, len_seq, len_seq]\n",
    "    # mask generation [batch_size, len_seq, len_seq]\n",
    "    attn_shape = [seq.size(0), seq.size(1), seq.size(1)]\n",
    "    # generate an upper left matrix\n",
    "    subsequence_mask = np.triu(np.ones(attn_shape), k=1)\n",
    "    subsequence_mask = torch.from_numpy(subsequence_mask).byte()\n",
    "    subsequence_mask = subsequence_mask.to(device)\n",
    "    return subsequence_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(attention_mask):\n",
    "    batch_size, len_seq = attention_mask.size()\n",
    "    attention_mask = attention_mask.data.eq(0).unsqueeze(1)\n",
    "    return attention_mask.expand(batch_size, len_seq, len_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, d_k, d_v, vocab_size, max_pos, n_layers, device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        # Tokenization\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # positional encodinng\n",
    "        self.pos_encoding = PositionalEncoding(d_model, max_pos, device)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, d_k, d_v) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, inputs, attention_mask):\n",
    "        ##\n",
    "        # inputs: [batch_size, seq_len]\n",
    "        ##\n",
    "        # [batch_size, seq_len, d_model]\n",
    "        outputs = self.embedding(inputs) + self.pos_encoding(inputs)\n",
    "        # 上三角掩码，防止看到未来的信息， [batch_size, seq_len, seq_len]\n",
    "        subsequence_mask = get_attn_subsequence_mask(inputs, self.device)\n",
    "        if attention_mask is not None:\n",
    "            # padding [batch_size, seq_len, seq_len]\n",
    "            attention_mask = get_attn_pad_mask(attention_mask)\n",
    "            # [batch_size, seq_len, seq_len]\n",
    "            attention_mask = torch.gt((attention_mask + subsequence_mask), 0)\n",
    "        else:\n",
    "            attention_mask = subsequence_mask.bool()\n",
    "        # calculate each layer\n",
    "        self_attns = []\n",
    "        for layer in self.layers:\n",
    "            # outputs: [batch_size, seq_len, d_model],\n",
    "            # self_attn: [batch_size, n_heads, seq_len, seq_len],\n",
    "            outputs, self_attn = layer(outputs, attention_mask)\n",
    "            self_attns.append(self_attn)\n",
    "        return outputs, self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, d_k, d_v, vocab_size, max_pos, n_layers, device):\n",
    "        super(GPTModel, self).__init__()\n",
    "        # decoder\n",
    "        self.decoder = Decoder(d_model, n_heads, d_ff, d_k, d_v, vocab_size, max_pos, n_layers, device)\n",
    "        # projection to vocabulary size\n",
    "        self.projection = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, attention_mask=None):\n",
    "        ##\n",
    "        # inputs: [batch_size, seq_len]\n",
    "        ##\n",
    "        # outputs: [batch_size, seq_len, d_model]\n",
    "        # self_attns: [n_layers, batch_size, n_heads, seq_len, seq_len]\n",
    "        outputs, self_attns = self.decoder(inputs, attention_mask)\n",
    "        # [batch_size, seq_len, vocab_size]\n",
    "        logits = self.projection(outputs)\n",
    "        return logits.view(-1, logits.size(-1)), self_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(4825, 768)\n",
      "    (pos_encoding): PositionalEncoding(\n",
      "      (pos_embedding): Embedding(1800, 768)\n",
      "    )\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (4): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (5): DecoderLayer(\n",
      "        (attention): MultiHeadAttention(\n",
      "          (w_q): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_k): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (w_v): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (fc): Linear(in_features=768, out_features=512, bias=False)\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (pos_ffn): PoswiseFeedForwardNet(\n",
      "          (fc): Sequential(\n",
      "            (0): Linear(in_features=768, out_features=2048, bias=False)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=768, bias=False)\n",
      "          )\n",
      "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (projection): Linear(in_features=768, out_features=4825, bias=True)\n",
      ")\n",
      "total_params:  37128409\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#from model import GPTModel\n",
    "\n",
    "\n",
    "def main():\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # 模型参数\n",
    "    model_param = {\n",
    "        \"d_model\": 768,  # embedding\n",
    "        \"d_ff\": 2048,  # forward feed layer\n",
    "        \"d_k\": 64,  # K \n",
    "        \"d_v\": 64,  # V \n",
    "        \"n_layers\": 6,  # decoding layer\n",
    "        \"n_heads\": 8,  # multi-head attenntion\n",
    "        \"max_pos\": 1800,  # positional encoding length\n",
    "        \"device\": device,  # device\n",
    "        \"vocab_size\": 4825  # vocabulary size\n",
    "    }\n",
    "    model = GPTModel(**model_param)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(model)\n",
    "    print(\"total_params: \", total_params)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish. words: 4825\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def build_vocab(file_path):\n",
    "    # Read all texts\n",
    "    texts = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as r:\n",
    "        for line in r:\n",
    "            if not line:\n",
    "                continue\n",
    "            line = json.loads(line)\n",
    "            question = line[\"question\"]\n",
    "            answer = line[\"answer\"]\n",
    "            texts.append(question)\n",
    "            texts.append(answer)\n",
    "    # 拆分 Token\n",
    "    words = set()\n",
    "    for t in texts:\n",
    "        if not t:\n",
    "            continue\n",
    "        for word in t.strip():\n",
    "            words.add(word)\n",
    "    words = list(words)\n",
    "    words.sort()\n",
    "    # Special Token\n",
    "    # pad、unk UNKNOWN、sep END\n",
    "    word2id = {\"<pad>\": 0, \"<unk>\": 1, \"<sep>\": 2}\n",
    "    # build up vocabulary list\n",
    "    word2id.update({word: i + len(word2id) for i, word in enumerate(words)})\n",
    "    id2word = list(word2id.keys())\n",
    "    vocab = {\"word2id\": word2id, \"id2word\": id2word}\n",
    "    vocab = json.dumps(vocab, ensure_ascii=False)\n",
    "    with open('data/vocab.json', 'w', encoding='utf-8') as w:\n",
    "        w.write(vocab)\n",
    "    print(f\"finish. words: {len(id2word)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    build_vocab(\"/Users/xiaonanliu/Desktop/Interview/Transformer/data/train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Tokenizer():\n",
    "\n",
    "    def __init__(self, vocab_path):\n",
    "        with open(vocab_path, \"r\", encoding=\"utf-8\") as r:\n",
    "            vocab = r.read()\n",
    "            if not vocab:\n",
    "                raise Exception(\"Empty vocabulary\")\n",
    "        vocab = json.loads(vocab)\n",
    "        self.word2id = vocab[\"word2id\"]\n",
    "        self.id2word = vocab[\"id2word\"]\n",
    "        self.pad_token = self.word2id[\"<pad>\"]\n",
    "        self.unk_token = self.word2id[\"<unk>\"]\n",
    "        self.sep_token = self.word2id[\"<sep>\"]\n",
    "\n",
    "    def encode(self, text, text1=None, max_length=128, pad_to_max_length=False):\n",
    "        tokens = [self.word2id[word] if word in self.word2id else self.unk_token for word in text]\n",
    "        tokens.append(self.sep_token)\n",
    "        if text1:\n",
    "            tokens.extend([self.word2id[word] if word in self.word2id else self.unk_token for word in text1])\n",
    "            tokens.append(self.sep_token)\n",
    "        att_mask = [1] * len(tokens)\n",
    "        if pad_to_max_length:\n",
    "            if len(tokens) > max_length:\n",
    "                tokens = tokens[0:max_length]\n",
    "                att_mask = att_mask[0:max_length]\n",
    "            elif len(tokens) < max_length:\n",
    "                tokens.extend([self.pad_token] * (max_length - len(tokens)))\n",
    "                att_mask.extend([0] * (max_length - len(att_mask)))\n",
    "        return tokens, att_mask\n",
    "\n",
    "    def decode(self, token):\n",
    "        if type(token) is tuple or type(token) is list:\n",
    "            return [self.id2word[n] for n in token]\n",
    "        else:\n",
    "            return self.id2word[token]\n",
    "\n",
    "    def get_vocab_size(self):\n",
    "        return len(self.id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token lens:  128\n",
      "encode:  [368, 1086, 16, 4, 1254, 663, 2, 368, 1086, 16, 4, 1254, 663, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "att_mask:  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "decode:  ['你', '好', ',', ' ', '小', '南', '<sep>', '你', '好', ',', ' ', '小', '南', '<sep>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "vocab_size 4825\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tokenizer = Tokenizer(vocab_path=\"data/vocab.json\")\n",
    "    encode, att_mask = tokenizer.encode(\"你好, 小南\", \"你好, 小南\", pad_to_max_length=True)\n",
    "    decode = tokenizer.decode(encode)\n",
    "    print(\"token lens: \", len(encode))\n",
    "    print(\"encode: \", encode)\n",
    "    print(\"att_mask: \", att_mask)\n",
    "    print(\"decode: \", decode)\n",
    "    print(\"vocab_size\", tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count:  10000\n",
      "val count:  1000\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "def split_dataset(file_path, output_path):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    datas = []\n",
    "    with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if not line or line == \"\":\n",
    "                continue\n",
    "            datas.append(line)\n",
    "    train = datas[0:10000]\n",
    "    val = datas[10000:11000]\n",
    "    with open(os.path.join(output_path, \"train.json\"), \"w\", encoding=\"utf-8\") as w:\n",
    "        for line in train:\n",
    "            w.write(line)\n",
    "            w.flush()\n",
    "\n",
    "    with open(os.path.join(output_path, \"val.json\"), \"w\", encoding=\"utf-8\") as w:\n",
    "        for line in val:\n",
    "            w.write(line)\n",
    "            w.flush()\n",
    "    print(\"train count: \", len(train))\n",
    "    print(\"val count: \", len(val))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = \"data/train.jsonl\"\n",
    "    split_dataset(file_path=file_path, output_path=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 35757 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 32451 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 38598 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 20998 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 24067 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-20': 681, '20-40': 2962, '40-60': 3623, '60-80': 1479, '80-100': 502, '100-120': 325, '120-140': 161, '140-160': 109, '160-180': 50, '180-200': 50, '200-220': 23, '220-240': 15, '240-260': 13, '260-280': 4, '280-300': 2, '300-320': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:238: RuntimeWarning: Glyph 37327 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 25968 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 37327 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 35757 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 32451 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 38598 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 20998 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 24067 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 24773 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "/Users/xiaonanliu/opt/anaconda3/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:201: RuntimeWarning: Glyph 20917 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "#from tokenizer import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "\n",
    "def get_num_tokens(file_path, tokenizer):\n",
    "    input_num_tokens = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as r:\n",
    "        for line in r:\n",
    "            line = json.loads(line)\n",
    "            question = line[\"question\"]\n",
    "            answer = line[\"answer\"]\n",
    "            tokens, att_mask = tokenizer.encode(question, answer)\n",
    "            input_num_tokens.append(len(tokens))\n",
    "    return input_num_tokens\n",
    "\n",
    "def count_intervals(num_tokens, interval):\n",
    "    max_value = max(num_tokens)\n",
    "    intervals_count = {}\n",
    "    for lower_bound in range(0, max_value + 1, interval):\n",
    "        upper_bound = lower_bound + interval\n",
    "        count = len([num for num in num_tokens if lower_bound <= num < upper_bound])\n",
    "        intervals_count[f\"{lower_bound}-{upper_bound}\"] = count\n",
    "    return intervals_count\n",
    "\n",
    "def main():\n",
    "    train_data_path = \"data/train.json\"\n",
    "    tokenizer = Tokenizer(\"data/vocab.json\")\n",
    "    input_num_tokens = get_num_tokens(train_data_path, tokenizer)\n",
    "    intervals_count = count_intervals(input_num_tokens, 20)\n",
    "    print(intervals_count)\n",
    "    x = [k for k, v in intervals_count.items()]\n",
    "    y = [v for k, v in intervals_count.items()]\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    bars = plt.bar(x, y)\n",
    "    plt.title('Token Distribution in Training Dataset')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.xticks(rotation=45)\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), va='bottom')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data_path, tokenizer, max_length) -> None:\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "        if data_path:\n",
    "            with open(data_path, \"r\", encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    if not line or line == \"\":\n",
    "                        continue\n",
    "                    json_line = json.loads(line)\n",
    "                    question = json_line[\"question\"]\n",
    "                    answer = json_line[\"answer\"]\n",
    "                    self.data.append({\n",
    "                        \"question\": question,\n",
    "                        \"answer\": answer\n",
    "                    })\n",
    "        print(\"data load ， size：\", len(self.data))\n",
    "\n",
    "    def preprocess(self, question, answer):\n",
    "        encode, att_mask = self.tokenizer.encode(question, answer, max_length=self.max_length, pad_to_max_length=True)\n",
    "        input_ids = encode[:-1]\n",
    "        att_mask = att_mask[:-1]\n",
    "        labels = encode[1:]\n",
    "        return input_ids, att_mask, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item_data = self.data[index]\n",
    "        input_ids, att_mask, labels = self.preprocess(**item_data)\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(np.array(input_ids)),\n",
    "            \"attention_mask\": torch.LongTensor(np.array(att_mask)),\n",
    "            \"labels\": torch.LongTensor(np.array(labels))\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Load Train Data...\n",
      "data load ， size： 10000\n",
      "Start Load Validation Data...\n",
      "data load ， size： 1000\n",
      "Start Training...\n",
      "Train Epoch: 0:   0%|          | 0/79 [09:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-91384f2f3eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-91384f2f3eb8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     train_model(\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-91384f2f3eb8>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, model_output_dir, writer)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Train Epoch: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    119\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_spawn_posix\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mForkServerProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/popen_spawn_posix.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfds_to_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from tokenizer import Tokenizer\n",
    "#from model import GPTModel\n",
    "#from qa_dataset import QADataset\n",
    "from tqdm import tqdm\n",
    "import time, sys, os\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion,\n",
    "                device, num_epochs, model_output_dir, writer):\n",
    "    batch_step = 0\n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        time1 = time.time()\n",
    "        model.train()\n",
    "        for index, data in enumerate(tqdm(train_loader, file=sys.stdout, desc=\"Train Epoch: \" + str(epoch))):\n",
    "            input_ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            labels = data['labels'].to(device, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, dec_self_attns = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.view(-1))\n",
    "            loss.backward()\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            writer.add_scalar('Loss/train', loss, batch_step)\n",
    "            batch_step += 1\n",
    "            # print loss every 100 times\n",
    "            if index % 1 == 0 or index == len(train_loader) - 1:\n",
    "                time2 = time.time()\n",
    "                tqdm.write(\n",
    "                    f\"{index}, epoch: {epoch} -loss: {str(loss)} ; lr: {optimizer.param_groups[0]['lr']} ;each step's time spent: {(str(float(time2 - time1) / float(index + 0.0001)))}\")\n",
    "        # validation\n",
    "        model.eval()\n",
    "        val_loss = validate_model(model, criterion, device, val_loader)\n",
    "        writer.add_scalar('Loss/val', val_loss, epoch)\n",
    "        print(f\"val loss: {val_loss} , epoch: {epoch}\")\n",
    "        # save the best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_path = os.path.join(model_output_dir, \"best.pt\")\n",
    "            print(\"Save Best Model To \", best_model_path, \", epoch: \", epoch)\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "        # save current model\n",
    "        last_model_path = os.path.join(model_output_dir, \"last.pt\")\n",
    "        print(\"Save Last Model To \", last_model_path, \", epoch: \", epoch)\n",
    "        torch.save(model.state_dict(), last_model_path)\n",
    "\n",
    "\n",
    "def validate_model(model, criterion, device, val_loader):\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(tqdm(val_loader, file=sys.stdout, desc=\"Validation Data\")):\n",
    "            input_ids = data['input_ids'].to(device, dtype=torch.long)\n",
    "            attention_mask = data['attention_mask'].to(device, dtype=torch.long)\n",
    "            labels = data['labels'].to(device, dtype=torch.long)\n",
    "            outputs, dec_self_attns = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels.view(-1))\n",
    "            running_loss += loss.item()\n",
    "    return running_loss / len(val_loader)\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_json_path = \"data/train.json\"  # Training set\n",
    "    val_json_path = \"data/val.json\"  # Validation set\n",
    "    vocab_path = \"data/vocab.json\"  # Vocabulary path\n",
    "    max_length = 120  # maximum length\n",
    "    epochs = 15 # epoch\n",
    "    batch_size = 128  # each batch 128 \n",
    "    lr = 1e-4  # leaerning rate\n",
    "    model_output_dir = \"output\"  # save model to dir\n",
    "    logs_dir = \"logs\"  # log dir\n",
    "    # device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # Tokenizer loading\n",
    "    tokenizer = Tokenizer(vocab_path)\n",
    "    # model parameter\n",
    "    model_param = {\n",
    "        \"d_model\": 768,  # embedding\n",
    "        \"d_ff\": 2048,  # forward feed net\n",
    "        \"d_k\": 64,  # K\n",
    "        \"d_v\": 64,  # V\n",
    "        \"n_layers\": 6,  # number of decoding layers\n",
    "        \"n_heads\": 8,  # number of multi-head attention heads\n",
    "        \"max_pos\": 1800,  # length of positional encoding\n",
    "        \"device\": device,  # device\n",
    "        \"vocab_size\": tokenizer.get_vocab_size(),  # vocabulary size\n",
    "    }\n",
    "    model = GPTModel(**model_param)\n",
    "    print(\"Start Load Train Data...\")\n",
    "    train_params = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 4,\n",
    "    }\n",
    "    training_set = QADataset(train_json_path, tokenizer, max_length)\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    print(\"Start Load Validation Data...\")\n",
    "    val_params = {\n",
    "        \"batch_size\": batch_size,\n",
    "        \"shuffle\": False,\n",
    "        \"num_workers\": 4,\n",
    "    }\n",
    "    val_set = QADataset(val_json_path, tokenizer, max_length)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "    # log \n",
    "    writer = SummaryWriter(logs_dir)\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.AdamW(params=model.parameters(), lr=lr)\n",
    "    # loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "    model = model.to(device)\n",
    "    # Start training\n",
    "    print(\"Start Training...\")\n",
    "    train_model(\n",
    "        model=model,\n",
    "        train_loader=training_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        num_epochs=epochs,\n",
    "        model_output_dir=model_output_dir,\n",
    "        writer=writer\n",
    "    )\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
